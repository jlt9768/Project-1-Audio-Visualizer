<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="utf-8" />
	<title>Web Audio Visualizer</title>
	<style>
	* { margin: 0; padding: 0;}
	body, html { height:100%; }
    canvas {
        background: black;
		position:absolute;
		width:100%;
		height:100%;
    }
      
	audio{
		position: absolute;
		left: 45%;
	
	}
	</style>
	<!-- Source: https://github.com/dataarts/dat.gui-->
	<script type="text/javascript" src="dat.gui.js"></script>
	<script>
	// An IIFE ("Iffy") - see the notes in mycourses
	(function(){
		"use strict";
		let Visualizer = function(){
			//Variables are added to the vis using this._______ and that will be the variable you use elsewhere
			
			this.Playing = 'media/Something_Elated.mp3';
			// Source: http://freemusicarchive.org/music/Broke_For_Free/Something_EP/Broke_For_Free_-_Something_EP_-_05_Something_Elated
			this.SOUND_1 = 'media/Something_Elated.mp3';
			// Source: http://freemusicarchive.org/music/BoxCat_Games/Nameless_the_Hackers_RPG_Soundtrack/BoxCat_Games_-_Nameless-_the_Hackers_RPG_Soundtrack_-_10_Epic_Song
			this.SOUND_2 = 'media/Epic_Song.mp3';
			// Source: http://freemusicarchive.org/music/Jahzzar/Travellers_Guide/Siesta
			this.SOUND_3 = 'media/Siesta.mp3';
			// Source: http://freemusicarchive.org/music/Blue_Wave_Theory/Surf_Music_Month_Challenge/Skyhawk_Beach_fade_in
			this.SOUND_4 = 'media/Skyhawk_Beach';
			// Source: http://freemusicarchive.org/music/Nublar/Inmerso/Nublar_-_Inmerso_-_02_Inmerso
			this.SOUND_5 = 'media/Inmerso';
			this.Invert = false;
			this.Tint = false;
			this.Noise = false;
			this.Data_Type = "Frequency";
			this.Visualizer_Type = "Bars";
			this.GoFullScreen = requestFullscreenOfCanvas;
			this.Volume = .2;
			this.Amplitude = 1;
			this.Tint_Color = [255,255,255];
			this.Num_Samples = 256;
		}
		let vis = new Visualizer();
		window.onload = function() {
			
			let gui = new dat.GUI();
			
			//Adds a folder section to the GUI
			let sounds = gui.addFolder('Tracks');
			
			//The context we want in our case the visualizer named Vis. 'Playing' is the named variable(this.Playing) from above, the variable name determines the label for the drop down. The value of 
			//the variable will be the default value out of the the ones listed below (if no value exists it will be blank). Setting up the options like this allows for what appears in the drop down
			//to be different from the value 'Playing' will get when selected. Playing will change based on the selected option;
			//
			let audioChangeController = sounds.add(vis, 'Playing', {Something_Elated: vis.SOUND_1, Epic_Song: vis.SOUND_2, Siesta: vis.SOUND_3, Skyhawk_Beach:vis.SOUND_4, Inmerso: vis.SOUND_5});		
			
			//Set up a controller on the drop down to change audio when the selected option is changed
			audioChangeController.onChange(function(){ playStream(audioElement,vis.Playing); });
			
			//Graph Effects
			let effectsG = gui.addFolder('Graph Effects');
			//Adding the two numbers after the value sets up a range slider that has min and max, in this instance .5 and 3 respectively
			effectsG.add(vis, 'Amplitude', .5,3);
			effectsG.add(vis, 'Num_Samples', [32,64,128,256]);
			effectsG.add(vis, 'Data_Type', {Frequency: "Frequency", Waveform: "Waveform"});
			effectsG.add(vis, 'Visualizer_Type', {Bar: "Bars", Lines: "Lines", Circles: "Circles", All: "All"});
			
			//Visual Effects
			let effectsV = gui.addFolder('Visual Effects');
			//If the variable being added is a boolean it will create a checkbox
			let effectsTint = effectsV.addFolder('Tint');
			effectsTint.add(vis, 'Tint');
			effectsTint.addColor(vis, 'Tint_Color');
			effectsV.add(vis, 'Invert');
			
			
			effectsV.add(vis, 'Noise');
			
			
			//AudioEffects
			let effectsA = gui.addFolder('Audio Effects');
			let audioVolumeController = effectsA.add(vis, 'Volume', 0,1);
			
			audioVolumeController.onChange(function(){ gainNode.gain.value = vis.Volume; });
			//If the variable being added is a function it creates a section that functions as a button
			gui.add(vis, 'GoFullScreen');
		};
		
		var audioElement;
		var analyserNode;
		var canvas,ctx;
		//var invert = false, tintRed = false, noise = false, lines = false;
		var maxRadius = 200;
		let canvasW, canvasH;
		var audioCtx, analyserNode, sourceNode, gainNode;
		let stars = [];
		function init(){
			// set up canvas stuff
			canvas = document.querySelector('canvas');
			canvasW = window.innerWidth;
			canvasH = window.innerHeight;
			canvas.width = canvasW;
			canvas.height = canvasH;
			ctx = canvas.getContext("2d");
			
			// get reference to <audio> element on page
			audioElement = document.querySelector('audio');
			
			// call our helper function and get an analyser node
			analyserNode = createWebAudioContextWithAnalyserNode(audioElement);
			
			// get sound track <select> and Full Screen button working
			//setupUI();
			
			// load and play default sound into audio element
			playStream(audioElement,vis.Playing);
			
			// start animation loop
			update();
		};
		
		
		function createWebAudioContextWithAnalyserNode(audioElement) {
			
			// create new AudioContext
			// The || is because WebAudio has not been standardized across browsers yet
			// http://webaudio.github.io/web-audio-api/#the-audiocontext-interface
			audioCtx = new (window.AudioContext || window.webkitAudioContext);
			
			// create an analyser node
			analyserNode = audioCtx.createAnalyser();
			
			gainNode = audioCtx.createGain();
			
			
			/*
			We will request NUM_SAMPLES number of samples or "bins" spaced equally 
			across the sound spectrum.
			
			If NUM_SAMPLES (fftSize) is 256, then the first bin is 0 Hz, the second is 172 Hz, 
			the third is 344Hz. Each bin contains a number between 0-255 representing 
			the amplitude of that frequency.
			*/ 
			
			// fft stands for Fast Fourier Transform
			analyserNode.fftSize = vis.Num_Samples;
			
			// this is where we hook up the <audio> element to the analyserNode
			sourceNode = audioCtx.createMediaElementSource(audioElement); 
			
			sourceNode.connect(gainNode);
			gainNode.connect(analyserNode);
			
			gainNode.gain.value = vis.Volume;
			
			// here we connect to the destination i.e. speakers
			analyserNode.connect(audioCtx.destination);
			return analyserNode;
		};
		
		function playStream(audioElement,path){
			audioElement.src = path;
			audioElement.play();
			//audioElement.volume = vis.Volume;
			//document.querySelector('#status').innerHTML = "Now playing: " + path;
		};
		
		function update() { 
			// this schedules a call to the update() method in 1/60 seconds
			requestAnimationFrame(update);
			//gainNode.gain.value = vis.Volume;
			/*
				Nyquist Theorem
				http://whatis.techtarget.com/definition/Nyquist-Theorem
				The array of data we get back is 1/2 the size of the sample rate 
			*/
			
     
			// create a new array of 8-bit integers (0-255)
			var data = new Uint8Array(vis.Num_Samples/2); 
			let wData = new Uint8Array(vis.Num_Samples/2); 
			// populate the array with the frequency data
			// notice these arrays can be passed "by reference" 
			if (vis.Data_Type == "Frequency")
			{
				analyserNode.getByteFrequencyData(data);
			}
			else
			{
				analyserNode.getByteTimeDomainData(data); // waveform data
			}
			analyserNode.getByteTimeDomainData(wData)
			// DRAW!
			ctx.clearRect(0,0,canvas.width,canvas.height);  
			
			//Starfield
			if (stars.length<vis.Num_Samples/2&&Math.random()<.5){ 
			let star = {
				x:0,
				y:0,
				velocityX:-5+Math.random()*10,
				velocityY:-5+Math.random()*10,
				color: [(Math.random()*255),(Math.random()*255),(Math.random()*255)]
			}
			stars.push(star);
			}
			for(let i=0;i<stars.length;i++){
				ctx.save();			
				stars[i].x += stars[i].velocityX; 
				stars[i].y += stars[i].velocityY;
				if(stars[i].x>canvasW/2 || stars[i].x<-canvasW/2){
						stars[i].x=0; 
						stars[i].y=0;
				}
				ctx.globalAlpha = (Math.abs(stars[i].x/(canvasW/2))/2 + Math.abs(stars[i].y/(canvasH/2))/2) + .1;
				ctx.fillStyle = 'rgb('+stars[i].color[0]+','+stars[i].color[1]+','+stars[i].color[2]+')';
				ctx.beginPath();
				ctx.arc(canvasW/2+stars[i].x, canvasH/2+stars[i].y, (Math.abs(stars[i].y/100+i/200))*(Math.pow(wData[i], 2)/5000), 0, 2 * Math.PI);
				ctx.fill();
				ctx.restore();
			}
			//
			
				
			var barWidth = 12 * (256/vis.Num_Samples);
			var barSpacing = 1;
			var barHeight = 5;
			var topSpacing = 400;
			
			var minLine = canvasH / (2 * vis.Amplitude);
			var pointSpacing = canvasW / data.length;
			let gradient = ctx.createLinearGradient(110, 0, canvasW - 110, 0);
			gradient.addColorStop(0, 'red');
			gradient.addColorStop(1 / 6, 'orange');
			gradient.addColorStop(2 / 6, 'yellow');
			gradient.addColorStop(3 / 6, 'green');
			gradient.addColorStop(4 / 6, 'blue');
			gradient.addColorStop(5 / 6, 'indigo');
			gradient.addColorStop(1, 'violet');
			
			// loop through the data and draw!
			
			for(var i=0; i<data.length; i++) { 								
				// the higher the amplitude of the sample (bin) the taller the bar
				// remember we have to draw our bars left-to-right and top-down
				if (vis.Visualizer_Type == "Bars" || vis.Visualizer_Type == "All")
				{
					ctx.fillStyle = gradient;
					ctx.save();				
					ctx.fillRect(i * (barWidth + barSpacing),canvasH / 2,barWidth,(barHeight + (data[i]/2))* vis.Amplitude);
					ctx.fillRect(i * (barWidth + barSpacing),canvasH / 2,barWidth,(-barHeight - (data[i]/2)) * vis.Amplitude); 
					ctx.restore();
				};
				
				if (vis.Visualizer_Type == "Circles" || vis.Visualizer_Type == "All")
				{
					ctx.save();   
					ctx.lineWidth = "1px";  
					
					ctx.beginPath();
					ctx.arc(i * (barWidth + barSpacing), (minLine + (data[i]/2)) * vis.Amplitude, barWidth, 0, Math.PI * 2, false); 
					ctx.closePath();
					ctx.fill();              
					ctx.stroke();   
					
					ctx.beginPath();
					ctx.arc(i * (barWidth + barSpacing), (minLine - (data[i]/2)) * vis.Amplitude, barWidth, 0, Math.PI * 2, false); 
					ctx.closePath();
					ctx.fill();              
					ctx.stroke();       
					ctx.restore(); 
				};
				
				/////CIRCLES REMOVED FOR NOW
				
				// red-ish circles
				//var percent = data[i] / 255;
				//var circleRadius = percent * maxRadius;
				//ctx.beginPath();
				//ctx.fillStyle= makeColor(255, 111, 111, .34 - percent/3.0);
				//ctx.arc(canvas.width/2, canvas.height/2, circleRadius , 0, 2 *
				//Math.PI, false);
				//ctx.fill();
				//ctx.closePath();
				//// blue-ish circles, bigger, more transparent
				//ctx.beginPath();
				//ctx.fillStyle= makeColor(0, 0, 255, .10 - percent/10.0 );
				//ctx.arc(canvas.width/2, canvas.height/2, circleRadius * 1.5, 0, 2 *
				//Math.PI, false);
				//ctx.fill();
				//ctx.closePath();
				//// yellow-ish circles, smaller
				//ctx.save();
				//ctx.beginPath();
				//ctx.fillStyle = makeColor(200, 200, 0, .5 - percent/5.0);
				//ctx.arc(canvas.width/2, canvas.height/2, circleRadius * .50, 0, 2 *
				//Math.PI, false);
				//ctx.fill();
				//ctx.closePath();
				//ctx.restore();				
			}
			
			
			if (vis.Visualizer_Type == "Lines" || vis.Visualizer_Type == "All")
			{
				////
				////Line Visualizer
				////
				ctx.save();
				ctx.beginPath();			
				ctx.lineWidth = 7;
				ctx.strokeStyle = gradient;
				for(let i=0; i<data.length; i++) {	
					if(i==0){
						ctx.moveTo(0,(minLine - (data[i]/2)) * vis.Amplitude);
					}else{
						ctx.lineTo((i * (pointSpacing)),(minLine - (data[i]/2)) * vis.Amplitude);
					};
				};
				ctx.stroke();
				
				for(let i=0; i<data.length; i++) {
					if(i==0){
						ctx.moveTo(0,(minLine + (data[i]/2)) * vis.Amplitude);
					}else{
						ctx.lineTo((i * (pointSpacing)),(minLine + (data[i]/2)) * vis.Amplitude);
					};
				};
				ctx.stroke();
				ctx.restore();
			}
			
			manipulatePixels();
		};
		
		// HELPER
		function makeColor(red, green, blue, alpha){
   			var color='rgba('+red+','+green+','+blue+', '+alpha+')';
   			return color;
		};
		
		 // FULL SCREEN MODE
		function requestFullscreen(element) {
			if (element.requestFullscreen) {
			  element.requestFullscreen();
			} else if (element.mozRequestFullscreen) {
			  element.mozRequestFullscreen();
			} else if (element.mozRequestFullScreen) { // camel-cased 'S' was changed to 's' in spec
			  element.mozRequestFullScreen();
			} else if (element.webkitRequestFullscreen) {
			  element.webkitRequestFullscreen();
			}
			// .. and do nothing if the method is not supported
		};
		function requestFullscreenOfCanvas() {
			if (canvas.requestFullscreen) {
			  canvas.requestFullscreen();
			} else if (canvas.mozRequestFullscreen) {
			  canvas.mozRequestFullscreen();
			} else if (canvas.mozRequestFullScreen) { // camel-cased 'S' was changed to 's' in spec
			  canvas.mozRequestFullScreen();
			} else if (canvas.webkitRequestFullscreen) {
			  canvas.webkitRequestFullscreen();
			}
			// .. and do nothing if the method is not supported
		};
			function manipulatePixels(){
			// i) Get all of the rgba pixel data of the canvas by grabbing the
			// ImageData Object
			// https://developer.mozilla.org/en-US/docs/Web/API/ImageData
			var imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
			// ii) imageData.data is an 8-bit typed array - values range from 0-255
			// imageData.data contains 4 values per pixel: 4 x canvas.width x
			// canvas.height = 1024000 values!
			// we’re looping through this 60 FPS - wow!
			var data = imageData.data;
			var length = data.length;
			var width = imageData.width;
			// iii) Iterate through each pixel
			// we step by 4 so that we can manipulate 1 pixel per iteration
			// data[i] is the red value
			// data[i+1] is the green value
			// data[i+2] is the blue value
			// data[i+3] is the alpha value
			for (var i = 0; i < length; i += 4){
				// iv) increase red value only
				
				if(vis.Tint){
					data[i] = data[i] + (vis.Tint_Color[0] / 2);
					data[i+1] = data[i+1] + (vis.Tint_Color[1] / 2);
					data[i+2] = data[i+2] + (vis.Tint_Color[2] / 2);
				}
				
				if(vis.Invert){
					var red = data[i], green = data[i+1], blue = data[i+2];
					data[i] = 255 - red; // set red value
					data[i+1] = 255 - green; // set blue value
					data[i+2] = 255 - blue; // set green value
					// data[i+3] is the alpha but we’re leaving that alone
				}
				if (vis.Noise && Math.random() < .10){
					data[i] = data[i +1] = data[i+2] = 128; // gray noise
					//data[i] = data[i +1] = data[i+2] = 255; // or white noise
					//data[i] = data[i +1] = data[i+2] = 0; // or black noise
					data[i+3] = 255; // alpha
				}				

			}
			// put the modified data back on the canvas
			ctx.putImageData(imageData, 0, 0);
		};

		
		window.addEventListener("load",init);
	}());
		
	</script>
</head>
<body>
	<canvas id="canvas" width="640" height="400"></canvas>
	<div id="controls">
		<audio controls loop></audio>
		<!--
		<label>Track: 
			<select id="trackSelect" >
				<option value="media/New Adventure Theme.mp3">New Adventure Theme</option>
				<option value="media/Peanuts Theme.mp3">Peanuts Theme</option>
				<option value="media/The Picard Song.mp3">The Picard Song</option>
			</select>
		</label>
		<button id="fsButton">Go Full Screen</button><br>
		<div>
			<label for="radiusSlider">Maximum radius</label>
			<input id="radiusSlider" type ="range" min ="50" max="200" step ="1" value ="200"/>
			<span id="sliderRadius">200</span>
		</div>
		<span>
			<label for="invertCheck">Invert</label>
			<input type="checkbox" id="invertCheck">
		</span>
		<span>
			<label for="tintRedCheck">Tint Red</label>
			<input type="checkbox" id="tintRedCheck">
		</span>
		<span>
			<label for="noiseCheck">Noise</label>
			<input type="checkbox" id="noiseCheck">
		</span>
		<span>
			<label for="linesCheck">Lines</label>
			<input type="checkbox" id="linesCheck">
		</span>
		<p id="status">???</p>
		-->
	</div>
</body>
</html>
